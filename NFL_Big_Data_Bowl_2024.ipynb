{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 60305,
          "databundleVersionId": 6654553,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30626,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "NFL Big Data Bowl 2024",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahilfatima/NFL-Big-Data-Bowl-2024/blob/main/NFL_Big_Data_Bowl_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'nfl-big-data-bowl-2024:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F60305%2F6654553%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240202%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240202T120005Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D6b9e94733853ad4d6dcc60b856f6af44c57526aa27ba0ca228dbecca981ce2e96fbe55d44cc77c5f06df984970c9984ec8d5560ad08f08c1481e11408c031ec9b0833ea47287400a8a85c089e3819e4842a2567296e87e424a535cc0a6b702cd94db823cde68f2bade8dd55993f8b972dc3ed2fe4f22e0217c49bb36c67028a85bbd6e8e302eaf096f55a77074a3899193d42f0052109366cc18f7b30c303a7bf50e1d997b3c214e496d7901fa771c63b501721f26478f71d4fd2ac863e46c3cd0683cf167080cba77989be82f173714b6c257e8da6edcaca0c1c32d7365c4486e6ea97a1f1bcc27c98a065ff120cb1edf1609c82ded92574bff7de6b1b174b9'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "eBTn8MX-sMLR"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.io as pio\n",
        "\n",
        "import datetime\n",
        "from colorama import Fore, Style, init\n",
        "import lightgbm as lgb\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, VotingClassifier\n",
        "from sklearn.metrics import accuracy_score, recall_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-01-08T17:54:45.1023Z",
          "iopub.execute_input": "2024-01-08T17:54:45.102802Z",
          "iopub.status.idle": "2024-01-08T17:54:47.647566Z",
          "shell.execute_reply.started": "2024-01-08T17:54:45.10277Z",
          "shell.execute_reply": "2024-01-08T17:54:47.64639Z"
        },
        "trusted": true,
        "id": "jePFSkiFsMLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Exploration and Preparation\n",
        "\n",
        "# Summarizing Data Frame and Color printing\n",
        "def PrintColor(text:str, color = Fore.BLUE, style = Style.BRIGHT):\n",
        "    \"Prints color outputs using colorama using a text F-string\";\n",
        "    print(style + color + text + Style.RESET_ALL);\n",
        "\n",
        "def summarize_dataframe(df):\n",
        "    summary_df = pd.DataFrame(df.dtypes, columns=['dtypes'])\n",
        "    summary_df['missing#'] = df.isna().sum().values*100\n",
        "    summary_df['missing%'] = (df.isna().sum().values*100)/len(df)\n",
        "    summary_df['uniques'] = df.nunique().values\n",
        "    summary_df['first_value'] = df.iloc[0].values\n",
        "    summary_df['last_value'] = df.iloc[len(df)-1].values\n",
        "    summary_df['count'] = df.count().values\n",
        "    #sum['skew'] = df.skew().values\n",
        "    desc = pd.DataFrame(df.describe().T)\n",
        "    summary_df['min'] = desc['min']\n",
        "    summary_df['max'] = desc['max']\n",
        "    summary_df['mean'] = desc['mean']\n",
        "    return summary_df\n",
        "\n",
        "# Importing data files\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        PrintColor(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-08T17:55:27.758391Z",
          "iopub.execute_input": "2024-01-08T17:55:27.758833Z",
          "iopub.status.idle": "2024-01-08T17:55:27.773672Z",
          "shell.execute_reply.started": "2024-01-08T17:55:27.758797Z",
          "shell.execute_reply": "2024-01-08T17:55:27.772495Z"
        },
        "trusted": true,
        "id": "NMGzTjomsMLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Games Data Inspection\n",
        "data_path1 = '/kaggle/input/nfl-big-data-bowl-2024/games.csv'\n",
        "games = pd.read_csv(data_path1, header=0)\n",
        "games.head(5).style.set_caption(\"Sample of the games data\"). \\\n",
        "set_properties(**{'border': '1.3px solid blue',\n",
        "                          'color': 'grey'})\n",
        "\n",
        "for col in games.columns:\n",
        "    msg = 'column: {:>10}\\t Percent of NaN value: {:.2f}%'.format(col,100*(games[col].isnull().sum()/games[col].shape[0]))\n",
        "    PrintColor(f\"\\n---> {msg}\");\n",
        "\n",
        "games.info()\n",
        "\n",
        "summarize_dataframe(games).style.background_gradient(cmap='Reds')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-08T18:02:00.058296Z",
          "iopub.execute_input": "2024-01-08T18:02:00.058765Z",
          "iopub.status.idle": "2024-01-08T18:02:00.210628Z",
          "shell.execute_reply.started": "2024-01-08T18:02:00.058727Z",
          "shell.execute_reply": "2024-01-08T18:02:00.209419Z"
        },
        "trusted": true,
        "id": "r82vf-_RsMLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Players Data Inspection\n",
        "data_path2 = '/kaggle/input/nfl-big-data-bowl-2024/players.csv'\n",
        "players = pd.read_csv(data_path2, header=0)\n",
        "players.head(5).style.set_caption(\"Sample of the players data\"). \\\n",
        "set_properties(**{'border': '1.3px solid blue',\n",
        "                          'color': 'grey'})\n",
        "\n",
        "for col in players.columns:\n",
        "    msg = 'column: {:>10}\\t Percent of NaN value: {:.2f}%'.format(col,100*(players[col].isnull().sum()/players[col].shape[0]))\n",
        "    PrintColor(f\"\\n---> {msg}\");\n",
        "\n",
        "players.info()\n",
        "\n",
        "summarize_dataframe(players).style.background_gradient(cmap='Reds')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-08T18:02:43.647142Z",
          "iopub.execute_input": "2024-01-08T18:02:43.647532Z",
          "iopub.status.idle": "2024-01-08T18:02:43.717433Z",
          "shell.execute_reply.started": "2024-01-08T18:02:43.647502Z",
          "shell.execute_reply": "2024-01-08T18:02:43.716361Z"
        },
        "trusted": true,
        "id": "IwWUBWxXsMLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Players Data Inspection\n",
        "data_path2 = '/kaggle/input/nfl-big-data-bowl-2024/players.csv'\n",
        "players = pd.read_csv(data_path2, header=0)\n",
        "\n",
        "# Display the first 5 rows of the players' data\n",
        "players.head(5).style.set_caption(\"Sample of the players data\"). \\\n",
        "    set_properties(**{'border': '1.3px solid blue', 'color': 'grey'})\n",
        "\n",
        "# Display percentage of NaN values for each column\n",
        "for col in players.columns:\n",
        "    msg = 'column: {:>10}\\t Percent of NaN value: {:.2f}%'.format(col, 100 * (players[col].isnull().sum() / players[col].shape[0]))\n",
        "    PrintColor(f\"\\n---> {msg}\")\n",
        "\n",
        "# Display general information about the players' data\n",
        "players.info()\n",
        "\n",
        "# Summarize the dataframe and apply a background gradient using seaborn\n",
        "summarize_dataframe(players).style.background_gradient(cmap='Reds')\n",
        "\n",
        "# Plot a bar chart to visualize the percentage of missing values in each column\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=players.columns, y=players.isnull().mean() * 100, palette='viridis')\n",
        "plt.title('Percentage of Missing Values in Each Column')\n",
        "plt.xlabel('Columns')\n",
        "plt.ylabel('Percentage of Missing Values')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-08T18:24:42.363753Z",
          "iopub.execute_input": "2024-01-08T18:24:42.364301Z",
          "iopub.status.idle": "2024-01-08T18:24:42.843588Z",
          "shell.execute_reply.started": "2024-01-08T18:24:42.364252Z",
          "shell.execute_reply": "2024-01-08T18:24:42.842795Z"
        },
        "trusted": true,
        "id": "9Fn0sQPDsMLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plays Data Inspection\n",
        "data_path3 = '/kaggle/input/nfl-big-data-bowl-2024/plays.csv'\n",
        "plays = pd.read_csv(data_path3, header=0)\n",
        "plays.head(5).style.set_caption(\"Sample of the plays data\"). \\\n",
        "set_properties(**{'border': '1.3px solid blue',\n",
        "                          'color': 'grey'})\n",
        "\n",
        "for col in plays.columns:\n",
        "    msg = 'column: {:>10}\\t Percent of NaN value: {:.2f}%'.format(col,100*(plays[col].isnull().sum()/plays[col].shape[0]))\n",
        "    PrintColor(f\"\\n---> {msg}\");\n",
        "\n",
        "plays.info()\n",
        "\n",
        "summarize_dataframe(plays).style.background_gradient(cmap='Reds')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-08T18:25:07.752636Z",
          "iopub.execute_input": "2024-01-08T18:25:07.753207Z",
          "iopub.status.idle": "2024-01-08T18:25:08.13338Z",
          "shell.execute_reply.started": "2024-01-08T18:25:07.753141Z",
          "shell.execute_reply": "2024-01-08T18:25:08.132472Z"
        },
        "trusted": true,
        "id": "wiQzXzx7sMLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plays Data Inspection\n",
        "data_path3 = '/kaggle/input/nfl-big-data-bowl-2024/plays.csv'\n",
        "plays = pd.read_csv(data_path3, header=0)\n",
        "plays.head(5).style.set_caption(\"Sample of the plays data\"). \\\n",
        "set_properties(**{'border': '1.3px solid blue',\n",
        "                          'color': 'grey'})\n",
        "\n",
        "for col in plays.columns:\n",
        "    msg = 'column: {:>10}\\t Percent of NaN value: {:.2f}%'.format(col,100*(plays[col].isnull().sum()/plays[col].shape[0]))\n",
        "    PrintColor(f\"\\n---> {msg}\");\n",
        "\n",
        "plays.info()\n",
        "\n",
        "summarize_dataframe(plays).style.background_gradient(cmap='Reds')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-08T18:26:30.208912Z",
          "iopub.execute_input": "2024-01-08T18:26:30.209384Z",
          "iopub.status.idle": "2024-01-08T18:26:30.531427Z",
          "shell.execute_reply.started": "2024-01-08T18:26:30.209347Z",
          "shell.execute_reply": "2024-01-08T18:26:30.530365Z"
        },
        "trusted": true,
        "id": "IbGv564TsMLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tackles Data Inspection\n",
        "data_path4 = '/kaggle/input/nfl-big-data-bowl-2024/tackles.csv'\n",
        "tackles = pd.read_csv(data_path4, header=0)\n",
        "tackles.head(5).style.set_caption(\"Sample of the tackles data\"). \\\n",
        "set_properties(**{'border': '1.3px solid blue',\n",
        "                          'color': 'grey'})\n",
        "\n",
        "for col in tackles.columns:\n",
        "    msg = 'column: {:>10}\\t Percent of NaN value: {:.2f}%'.format(col,100*(tackles[col].isnull().sum()/tackles[col].shape[0]))\n",
        "    PrintColor(f\"\\n---> {msg}\");\n",
        "\n",
        "tackles.info()\n",
        "\n",
        "summarize_dataframe(tackles).style.background_gradient(cmap='Reds')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-08T18:27:31.475072Z",
          "iopub.execute_input": "2024-01-08T18:27:31.47548Z",
          "iopub.status.idle": "2024-01-08T18:27:31.563044Z",
          "shell.execute_reply.started": "2024-01-08T18:27:31.475449Z",
          "shell.execute_reply": "2024-01-08T18:27:31.561927Z"
        },
        "trusted": true,
        "id": "IXC3bzBrsMLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new variable in 'tackles' dataframe to hold the maximum value\n",
        "tackles['attack'] = tackles[['tackle', 'assist', 'forcedFumble']].max(axis=1)\n",
        "# Merge 'tackles' with 'players' on 'nflId'\n",
        "final_df = pd.merge(tackles, players[['nflId', 'height', 'weight', 'birthDate', 'collegeName', 'position']], on='nflId', how='left')\n",
        "# Merge 'tackles' with 'games' on 'gameId'\n",
        "final_df = pd.merge(final_df, games[['gameId', 'week', 'homeTeamAbbr', 'visitorTeamAbbr']], on='gameId', how='left')\n",
        "# Merge 'tackles' with 'plays' on 'gameId' and 'playId'\n",
        "final_df = pd.merge(final_df, plays[['gameId', 'playId', 'quarter', 'down', 'yardsToGo', 'possessionTeam', 'defensiveTeam',\n",
        "                                    'gameClock', 'yardlineNumber', 'preSnapHomeScore',\n",
        "                                    'preSnapVisitorScore', 'defendersInTheBox', 'preSnapHomeTeamWinProbability',\n",
        "                                    'preSnapVisitorTeamWinProbability']], on=['gameId', 'playId'], how='left')\n",
        "\n",
        "# drop tackle, assist, forcedFumble, pff_missedTackle\n",
        "final_df = final_df.drop(columns=['tackle', 'assist', 'forcedFumble', 'pff_missedTackle'])\n",
        "\n",
        "# Display the final dataframe\n",
        "PrintColor(\"Sample of New Data Frame:\")\n",
        "print(final_df.head())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-08T18:27:51.834023Z",
          "iopub.execute_input": "2024-01-08T18:27:51.834945Z",
          "iopub.status.idle": "2024-01-08T18:27:51.895538Z",
          "shell.execute_reply.started": "2024-01-08T18:27:51.834897Z",
          "shell.execute_reply": "2024-01-08T18:27:51.894398Z"
        },
        "trusted": true,
        "id": "59RQuPb3sMLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for non-numeric columns\n",
        "non_numeric_columns_final_df = final_df.select_dtypes(exclude=[np.number]).columns\n",
        "# Display the non-numeric columns in the merged data\n",
        "PrintColor(\"Non-Numeric Columns in 'final_df' DataFrame:\")\n",
        "print(non_numeric_columns_final_df)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-08T18:28:16.419525Z",
          "iopub.execute_input": "2024-01-08T18:28:16.420954Z",
          "iopub.status.idle": "2024-01-08T18:28:16.434295Z",
          "shell.execute_reply.started": "2024-01-08T18:28:16.42091Z",
          "shell.execute_reply": "2024-01-08T18:28:16.432861Z"
        },
        "trusted": true,
        "id": "CLJr9x_XsMLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_height_to_inches(height):\n",
        "    if isinstance(height, int):\n",
        "        return height  # Return the height unchanged if it's already an integer\n",
        "    else:\n",
        "        feet, inches = map(int, height.split('-'))\n",
        "        return feet * 12 + inches\n",
        "\n",
        "# Apply the function to the 'height' column\n",
        "final_df['height'] = final_df['height'].apply(convert_height_to_inches)\n",
        "\n",
        "# Convert gameClock from the given format to seconds\n",
        "def convert_gameclock_to_seconds(gameclock):\n",
        "    if pd.isna(gameclock):  # Handle missing values\n",
        "        return np.nan\n",
        "\n",
        "    minutes, seconds = map(int, gameclock.split(':'))\n",
        "    total_seconds = minutes * 60 + seconds\n",
        "    return total_seconds\n",
        "\n",
        "# Apply the conversion function to the 'gameClock' column\n",
        "final_df['gameClockSeconds'] = final_df['gameClock'].apply(convert_gameclock_to_seconds)\n",
        "# Drop the original 'gameClock' column\n",
        "final_df.drop('gameClock', axis=1, inplace=True)\n",
        "\n",
        "# 'birthDate' is in string format, convert it to datetime\n",
        "final_df['birthDate'] = pd.to_datetime(final_df['birthDate'], errors='coerce')\n",
        "# Calculate age from 'birthDate'\n",
        "final_df['age'] = (datetime.datetime.now() - final_df['birthDate']).dt.days // 365\n",
        "# Handle NaN values by replacing them with the average age\n",
        "average_age = final_df['age'].mean()\n",
        "final_df['age'].fillna(average_age, inplace=True)\n",
        "# Drop the original 'birthDate' column\n",
        "final_df.drop('birthDate', axis=1, inplace=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-08T18:29:13.437279Z",
          "iopub.execute_input": "2024-01-08T18:29:13.437692Z",
          "iopub.status.idle": "2024-01-08T18:29:13.556109Z",
          "shell.execute_reply.started": "2024-01-08T18:29:13.437662Z",
          "shell.execute_reply": "2024-01-08T18:29:13.554918Z"
        },
        "trusted": true,
        "id": "fJ1fMfcOsMLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encodoing cateogrical values to numerical values\n",
        "# List of columns to be encoded\n",
        "columns_to_encode = ['collegeName', 'position', 'homeTeamAbbr', 'visitorTeamAbbr', 'possessionTeam', 'defensiveTeam']\n",
        "# Dictionary to store mappings\n",
        "encoding_mappings = {}\n",
        "# Encode each column\n",
        "label_encoder = LabelEncoder()\n",
        "for column in columns_to_encode:\n",
        "    # Fill NaN values with a placeholder before encoding\n",
        "    final_df[column].fillna('NaN', inplace=True)\n",
        "\n",
        "    # Fit and transform with LabelEncoder\n",
        "    final_df[column] = label_encoder.fit_transform(final_df[column])\n",
        "\n",
        "    # Store the mappings\n",
        "    encoding_mappings[column] = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-08T18:29:52.910678Z",
          "iopub.execute_input": "2024-01-08T18:29:52.911069Z",
          "iopub.status.idle": "2024-01-08T18:29:52.929837Z",
          "shell.execute_reply.started": "2024-01-08T18:29:52.911024Z",
          "shell.execute_reply": "2024-01-08T18:29:52.928789Z"
        },
        "trusted": true,
        "id": "7Nx8RgwxsMLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the mappings\n",
        "print(\"Encoding Mappings:\")\n",
        "for column, mapping in encoding_mappings.items():\n",
        "    print(f\"\\n{column} Mapping:\")\n",
        "    print(mapping)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-08T18:29:57.845614Z",
          "iopub.execute_input": "2024-01-08T18:29:57.846013Z",
          "iopub.status.idle": "2024-01-08T18:29:57.853232Z",
          "shell.execute_reply.started": "2024-01-08T18:29:57.845981Z",
          "shell.execute_reply": "2024-01-08T18:29:57.852095Z"
        },
        "trusted": true,
        "id": "Aw4kVddssMLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the  DataFrame\n",
        "PrintColor(\"Sample of Final Data Frame:\")\n",
        "print(final_df.head())\n",
        "print(final_df)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-08T18:30:12.923272Z",
          "iopub.execute_input": "2024-01-08T18:30:12.923667Z",
          "iopub.status.idle": "2024-01-08T18:30:12.952826Z",
          "shell.execute_reply.started": "2024-01-08T18:30:12.923636Z",
          "shell.execute_reply": "2024-01-08T18:30:12.951737Z"
        },
        "trusted": true,
        "id": "jBfqrE5HsMLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Correlation Analysis\n",
        "# Check correlation between variables and 'attack' in 'final_df' DataFrame\n",
        "correlation_final_df = final_df.corr()['attack']\n",
        "# Display the correlation values\n",
        "PrintColor(\"Correlation with 'attack' in 'final_df' DataFrame:\")\n",
        "print(correlation_final_df)\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = final_df.corr()\n",
        "# Set up the matplotlib figure\n",
        "plt.figure(figsize=(12, 10))\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=.5)\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-08T18:31:46.020836Z",
          "iopub.execute_input": "2024-01-08T18:31:46.021273Z",
          "iopub.status.idle": "2024-01-08T18:31:47.931368Z",
          "shell.execute_reply.started": "2024-01-08T18:31:46.021237Z",
          "shell.execute_reply": "2024-01-08T18:31:47.930524Z"
        },
        "trusted": true,
        "id": "KrfOk0Z-sMLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## Modeling\n",
        "# Feature Importance Analysis\n",
        "# Drop rows with NaN values\n",
        "final_df.dropna(inplace=True)\n",
        "# Define features (X) and target variable (y)\n",
        "X = final_df.drop(['attack'], axis=1)\n",
        "y = final_df['attack']\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# Create a Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "# Fit the model\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "# Get feature importances\n",
        "feature_importances = rf_classifier.feature_importances_\n",
        "# Create a DataFrame to visualize feature importances\n",
        "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
        "# Sort the DataFrame by importance\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "# Plot the feature importances\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
        "plt.xlabel('Importance')\n",
        "plt.title('Feature Importances')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Based on feature selection,\n",
        "# Set a threshold for feature importance\n",
        "threshold = 0.05\n",
        "# Filter features above the threshold\n",
        "selected_features = feature_importance_df[feature_importance_df['Importance'] >= threshold]['Feature']\n",
        "# Subset the original DataFrame with the selected features\n",
        "X_selected = X[selected_features]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
        "print('X_train:')\n",
        "print(X_train)\n",
        "print('X_test:')\n",
        "print(X_test)\n",
        "print('y_train:')\n",
        "print(y_train)\n",
        "print('y_test:')\n",
        "print(y_test)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-08T18:32:10.267299Z",
          "iopub.execute_input": "2024-01-08T18:32:10.267692Z",
          "iopub.status.idle": "2024-01-08T18:32:14.741235Z",
          "shell.execute_reply.started": "2024-01-08T18:32:10.26766Z",
          "shell.execute_reply": "2024-01-08T18:32:14.740161Z"
        },
        "trusted": true,
        "id": "vdTx6BxtsMLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression Model\n",
        "# Initialize the Logistic Regression model\n",
        "model1 = LogisticRegression()\n",
        "# Train the model\n",
        "model1.fit(X_train, y_train)\n",
        "# Make predictions on the test set\n",
        "predictions = model1.predict(X_test)\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f\"Accuracy of the model using Logistic Regresssion Classifier: {accuracy}\")\n",
        "\n",
        "# Random Forest Model\n",
        "# Initialize the Random Forest model\n",
        "model2 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "# Train the model\n",
        "model2.fit(X_train, y_train)\n",
        "# Make predictions on the test set\n",
        "predictions = model2.predict(X_test)\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f\"Accuracy of the model using Random Forest Classifier : {accuracy}\")\n",
        "\n",
        "# SVM Model\n",
        "# Scale the features (important for SVM)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_selected)\n",
        "# Try different kernels\n",
        "kernels = ['linear', 'rbf', 'poly', 'sigmoid']\n",
        "for kernel in kernels:\n",
        "    # Initialize the SVM model\n",
        "    model3 = SVC(kernel=kernel, random_state=42)\n",
        "    # Train the model\n",
        "    model3.fit(X_train, y_train)\n",
        "    # Make predictions on the test set\n",
        "    predictions = model3.predict(X_test)\n",
        "    # Evaluate accuracy\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    print(f\"Accuracy of the model using SVM Claissifier with {kernel} kernel: {accuracy}\")\n",
        "\n",
        "# Adaboost Model\n",
        "# Initialize the AdaBoost model\n",
        "model4 = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
        "# Train the model\n",
        "model4.fit(X_train, y_train)\n",
        "# Make predictions on the test set\n",
        "predictions = model4.predict(X_test)\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f\"Accuracy of the model using Adaboost Classifier: {accuracy}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-08T18:32:59.495372Z",
          "iopub.execute_input": "2024-01-08T18:32:59.495839Z",
          "iopub.status.idle": "2024-01-08T18:33:50.03856Z",
          "shell.execute_reply.started": "2024-01-08T18:32:59.495799Z",
          "shell.execute_reply": "2024-01-08T18:33:50.037308Z"
        },
        "trusted": true,
        "id": "Tks9B7yBsMLa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}